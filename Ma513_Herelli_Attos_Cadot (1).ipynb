{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importation Des Bibliothèques**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import (\n",
    "    BertTokenizerFast,\n",
    "    AutoModelForTokenClassification,\n",
    "    DataCollatorForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    pipeline\n",
    ")\n",
    "from datasets import DatasetDict, Dataset, Features, Sequence, ClassLabel, Value\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Configuration Des Paramètres Globaux**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 135\n",
    "TRAIN_BATCH_SIZE = 32  # Réduit pour mieux gérer la mémoire GPU\n",
    "VALID_BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 3e-5\n",
    "BASE_MODEL_PATH = \"dslim/bert-base-NER\"\n",
    "MODEL_PATH = \"./data/bert-base-NER_model\"\n",
    "\n",
    "# Chemins vers les fichiers de données\n",
    "TRAINING_FILE = r\"D:\\AERO_5\\Projet atilla\\Projet atilla\\NER-TRAINING.jsonlines\"\n",
    "VALIDATION_FILE = r\"D:\\AERO_5\\Projet atilla\\Projet atilla\\NER-VALIDATION.jsonlines\"\n",
    "TESTING_FILE = r\"D:\\AERO_5\\Projet atilla\\Projet atilla\\NER-TESTING.jsonlines\"\n",
    "\n",
    "# Chemins ou seront stockées les données\n",
    "TESTING_OUTPUT_FILE = \"D:/AERO_5/Projet atilla/Projet atilla/NER-TESTING-PREDICTED.jsonlines\"\n",
    "VALIDATION_OUTPUT_FILE = \"D:/AERO_5/Projet atilla/Projet atilla/NER-VALIDATION-PREDICTED.jsonlines\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Chargement Du Tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZER = BertTokenizerFast.from_pretrained(BASE_MODEL_PATH, do_lower_case=True)\n",
    "\n",
    "# Mapping des labels\n",
    "ID2LABEL = {\n",
    "    0: \"B-Action\",\n",
    "    1: \"B-Entity\",\n",
    "    2: \"B-Modifier\",\n",
    "    3: \"I-Action\",\n",
    "    4: \"I-Entity\",\n",
    "    5: \"I-Modifier\",\n",
    "    6: \"O\"\n",
    "}\n",
    "LABEL2ID = {v: k for k, v in ID2LABEL.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Chargement Des Données**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour charger un fichier JSONlines\n",
    "def load_and_prepare_data(file_path):\n",
    "    \"\"\"Charge un fichier JSONlines et retourne les données sous forme de liste.\"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Conversion En Dataset Avec Labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_dataset_with_labels(data_section, labels):\n",
    "    \"\"\"Convertit une section de données en Dataset avec labels dynamiques.\"\"\"\n",
    "    has_ner_tags = \"ner_tags\" in data_section[0]\n",
    "    \n",
    "    features = Features({\n",
    "        \"id\": Value(\"int64\"),\n",
    "        \"tokens\": Sequence(Value(\"string\")),\n",
    "        **({\"ner_tags\": Sequence(ClassLabel(names=labels))} if has_ner_tags else {})\n",
    "    })\n",
    "    \n",
    "    dataset_dict = {\n",
    "        \"id\": [example[\"unique_id\"] for example in data_section],\n",
    "        \"tokens\": [example[\"tokens\"] for example in data_section],\n",
    "    }\n",
    "    if has_ner_tags:\n",
    "        dataset_dict[\"ner_tags\"] = [example[\"ner_tags\"] for example in data_section]\n",
    "    \n",
    "    return Dataset.from_dict(dataset_dict, features=features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Chargement Des Données**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données\n",
    "train_data = load_and_prepare_data(TRAINING_FILE)\n",
    "validation_data = load_and_prepare_data(VALIDATION_FILE)\n",
    "test_data = load_and_prepare_data(TESTING_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Création De La DataSet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_labels = list(ID2LABEL.values())\n",
    "ner_data = DatasetDict({\n",
    "    \"train\": convert_to_dataset_with_labels(train_data, ner_labels),\n",
    "    \"validation\": convert_to_dataset_with_labels(validation_data, ner_labels),\n",
    "    \"test\": convert_to_dataset_with_labels(test_data, ner_labels)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tokenisation et alignement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4876/4876 [00:00<00:00, 11868.69 examples/s]\n",
      "Map: 100%|██████████| 1044/1044 [00:00<00:00, 12958.29 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_and_align_labels(examples, label_all_tokens=True):\n",
    "    \"\"\"Tokenise les phrases et aligne les étiquettes avec les tokens.\"\"\"\n",
    "    tokenized_inputs = TOKENIZER(\n",
    "        examples[\"tokens\"],\n",
    "        truncation=True,\n",
    "        is_split_into_words=True\n",
    "    )\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "# Tokenisation des datasets\n",
    "tokenized_datasets = DatasetDict({\n",
    "    key: dataset.map(tokenize_and_align_labels, batched=True) if key != \"test\" else dataset\n",
    "    for key, dataset in ner_data.items()\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Initialisation du modèle et des arguments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dslim/bert-base-NER and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([9]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([9, 768]) in the checkpoint and torch.Size([7, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "ner_model = AutoModelForTokenClassification.from_pretrained(\n",
    "    BASE_MODEL_PATH, \n",
    "    num_labels=len(ner_labels), \n",
    "    id2label=ID2LABEL, \n",
    "    label2id=LABEL2ID,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "ner_model.to(DEVICE)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    per_device_train_batch_size=TRAIN_BATCH_SIZE,\n",
    "    per_device_eval_batch_size=VALID_BATCH_SIZE,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    weight_decay=0.01\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(TOKENIZER)\n",
    "metric = evaluate.load(\"seqeval\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Fonction De Calcul Des Métriques**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    pred_logits, labels = eval_preds\n",
    "    pred_logits = np.argmax(pred_logits, axis=2)\n",
    "    predictions = [[ID2LABEL[p] for p, l in zip(prediction, label) if l != -100] for prediction, label in zip(pred_logits, labels)]\n",
    "    true_labels = [[ID2LABEL[l] for p, l in zip(prediction, label) if l != -100] for prediction, label in zip(pred_logits, labels)]\n",
    "    return metric.compute(predictions=predictions, references=true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Entrainement Du Modèle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\safah\\AppData\\Local\\Temp\\ipykernel_28500\\1281199915.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "                                                    \n",
      " 10%|█         | 153/1530 [13:15<1:22:39,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.37988871335983276, 'eval_Action': {'precision': 0.6014319809069213, 'recall': 0.5009940357852882, 'f1': 0.5466377440347072, 'number': 503}, 'eval_Entity': {'precision': 0.39143426294820716, 'recall': 0.31116389548693585, 'f1': 0.34671371857079836, 'number': 1263}, 'eval_Modifier': {'precision': 0.6284153005464481, 'recall': 0.4107142857142857, 'f1': 0.4967602591792657, 'number': 280}, 'eval_overall_precision': 0.47322540473225405, 'eval_overall_recall': 0.37145650048875856, 'eval_overall_f1': 0.41621029572836804, 'eval_overall_accuracy': 0.8637931560792454, 'eval_runtime': 41.1563, 'eval_samples_per_second': 25.367, 'eval_steps_per_second': 1.604, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 20%|██        | 306/1530 [29:18<1:40:28,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3448692262172699, 'eval_Action': {'precision': 0.6270783847980997, 'recall': 0.5248508946322068, 'f1': 0.5714285714285715, 'number': 503}, 'eval_Entity': {'precision': 0.44842562432138977, 'recall': 0.3269992082343626, 'f1': 0.3782051282051282, 'number': 1263}, 'eval_Modifier': {'precision': 0.6948051948051948, 'recall': 0.3821428571428571, 'f1': 0.4930875576036866, 'number': 280}, 'eval_overall_precision': 0.5240641711229946, 'eval_overall_recall': 0.3831867057673509, 'eval_overall_f1': 0.4426877470355731, 'eval_overall_accuracy': 0.8698983485454379, 'eval_runtime': 54.5619, 'eval_samples_per_second': 19.134, 'eval_steps_per_second': 1.21, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \n",
      " 30%|███       | 459/1530 [1:12:44<1:46:05,  5.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3617432713508606, 'eval_Action': {'precision': 0.5885416666666666, 'recall': 0.6739562624254473, 'f1': 0.6283595922150139, 'number': 503}, 'eval_Entity': {'precision': 0.4775900073475386, 'recall': 0.5146476642913698, 'f1': 0.49542682926829273, 'number': 1263}, 'eval_Modifier': {'precision': 0.5853658536585366, 'recall': 0.6, 'f1': 0.5925925925925926, 'number': 280}, 'eval_overall_precision': 0.5202338129496403, 'eval_overall_recall': 0.5654936461388075, 'eval_overall_f1': 0.54192037470726, 'eval_overall_accuracy': 0.8865960499404744, 'eval_runtime': 53.8697, 'eval_samples_per_second': 19.38, 'eval_steps_per_second': 1.225, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 500/1530 [1:16:47<1:22:46,  4.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3223, 'grad_norm': 3.523790121078491, 'learning_rate': 2.019607843137255e-05, 'epoch': 3.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      " 40%|████      | 612/1530 [1:29:33<1:25:05,  5.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3881355822086334, 'eval_Action': {'precision': 0.6325088339222615, 'recall': 0.7117296222664016, 'f1': 0.6697848456501404, 'number': 503}, 'eval_Entity': {'precision': 0.48, 'recall': 0.5700712589073634, 'f1': 0.521172638436482, 'number': 1263}, 'eval_Modifier': {'precision': 0.5794701986754967, 'recall': 0.625, 'f1': 0.6013745704467354, 'number': 280}, 'eval_overall_precision': 0.5291385135135135, 'eval_overall_recall': 0.6124144672531769, 'eval_overall_f1': 0.5677390122338015, 'eval_overall_accuracy': 0.8845508104642998, 'eval_runtime': 54.2382, 'eval_samples_per_second': 19.248, 'eval_steps_per_second': 1.217, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      " 50%|█████     | 765/1530 [1:45:44<49:22,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4383243918418884, 'eval_Action': {'precision': 0.5658682634730539, 'recall': 0.7514910536779325, 'f1': 0.645602049530316, 'number': 503}, 'eval_Entity': {'precision': 0.4813172894236859, 'recall': 0.601741884402217, 'f1': 0.5348346235045742, 'number': 1263}, 'eval_Modifier': {'precision': 0.571875, 'recall': 0.6535714285714286, 'f1': 0.61, 'number': 280}, 'eval_overall_precision': 0.514608492403584, 'eval_overall_recall': 0.6456500488758553, 'eval_overall_f1': 0.5727292434424452, 'eval_overall_accuracy': 0.8802466497756342, 'eval_runtime': 46.4966, 'eval_samples_per_second': 22.453, 'eval_steps_per_second': 1.419, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      " 60%|██████    | 918/1530 [1:59:32<44:15,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.49871790409088135, 'eval_Action': {'precision': 0.650853889943074, 'recall': 0.6819085487077535, 'f1': 0.6660194174757282, 'number': 503}, 'eval_Entity': {'precision': 0.5167883211678832, 'recall': 0.5605700712589073, 'f1': 0.5377895936194454, 'number': 1263}, 'eval_Modifier': {'precision': 0.5946843853820598, 'recall': 0.6392857142857142, 'f1': 0.6161790017211703, 'number': 280}, 'eval_overall_precision': 0.5595996360327571, 'eval_overall_recall': 0.6011730205278593, 'eval_overall_f1': 0.5796418473138549, 'eval_overall_accuracy': 0.8885802374919869, 'eval_runtime': 44.9046, 'eval_samples_per_second': 23.249, 'eval_steps_per_second': 1.47, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 1000/1530 [2:23:13<5:24:01, 36.68s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0767, 'grad_norm': 2.3065361976623535, 'learning_rate': 1.0392156862745098e-05, 'epoch': 6.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      " 70%|███████   | 1071/1530 [2:29:12<22:21,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5407664775848389, 'eval_Action': {'precision': 0.6456140350877193, 'recall': 0.731610337972167, 'f1': 0.6859273066169618, 'number': 503}, 'eval_Entity': {'precision': 0.5257378174330817, 'recall': 0.6064924782264449, 'f1': 0.5632352941176471, 'number': 1263}, 'eval_Modifier': {'precision': 0.624561403508772, 'recall': 0.6357142857142857, 'f1': 0.6300884955752212, 'number': 280}, 'eval_overall_precision': 0.5674740484429066, 'eval_overall_recall': 0.6412512218963832, 'eval_overall_f1': 0.6021110601193207, 'eval_overall_accuracy': 0.8876339326597271, 'eval_runtime': 41.2377, 'eval_samples_per_second': 25.317, 'eval_steps_per_second': 1.6, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      " 80%|████████  | 1224/1530 [2:46:09<24:07,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.56827312707901, 'eval_Action': {'precision': 0.6604477611940298, 'recall': 0.7037773359840954, 'f1': 0.6814244465832531, 'number': 503}, 'eval_Entity': {'precision': 0.55859375, 'recall': 0.5661124307205068, 'f1': 0.5623279591034211, 'number': 1263}, 'eval_Modifier': {'precision': 0.6547619047619048, 'recall': 0.5892857142857143, 'f1': 0.6203007518796992, 'number': 280}, 'eval_overall_precision': 0.5967117988394585, 'eval_overall_recall': 0.603128054740958, 'eval_overall_f1': 0.5999027710257657, 'eval_overall_accuracy': 0.8914496779510974, 'eval_runtime': 42.1152, 'eval_samples_per_second': 24.789, 'eval_steps_per_second': 1.567, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      " 90%|█████████ | 1377/1530 [3:01:26<09:46,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5857949256896973, 'eval_Action': {'precision': 0.6426116838487973, 'recall': 0.7435387673956262, 'f1': 0.6894009216589863, 'number': 503}, 'eval_Entity': {'precision': 0.5370755370755371, 'recall': 0.613618368962787, 'f1': 0.5728011825572802, 'number': 1263}, 'eval_Modifier': {'precision': 0.6140939597315436, 'recall': 0.6535714285714286, 'f1': 0.6332179930795848, 'number': 280}, 'eval_overall_precision': 0.5733964700817907, 'eval_overall_recall': 0.6510263929618768, 'eval_overall_f1': 0.609750514991989, 'eval_overall_accuracy': 0.8904423211941757, 'eval_runtime': 36.9882, 'eval_samples_per_second': 28.225, 'eval_steps_per_second': 1.784, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 1500/1530 [3:11:32<02:18,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0231, 'grad_norm': 0.7719393968582153, 'learning_rate': 5.882352941176471e-07, 'epoch': 9.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "100%|██████████| 1530/1530 [3:14:55<00:00,  7.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5903509855270386, 'eval_Action': {'precision': 0.6384479717813051, 'recall': 0.7196819085487077, 'f1': 0.6766355140186916, 'number': 503}, 'eval_Entity': {'precision': 0.5459811730629979, 'recall': 0.5969912905779889, 'f1': 0.5703479576399395, 'number': 1263}, 'eval_Modifier': {'precision': 0.6492537313432836, 'recall': 0.6214285714285714, 'f1': 0.635036496350365, 'number': 280}, 'eval_overall_precision': 0.5821299638989169, 'eval_overall_recall': 0.6304985337243402, 'eval_overall_f1': 0.6053496011262318, 'eval_overall_accuracy': 0.8916023077627522, 'eval_runtime': 36.5057, 'eval_samples_per_second': 28.598, 'eval_steps_per_second': 1.808, 'epoch': 10.0}\n",
      "{'train_runtime': 11695.7968, 'train_samples_per_second': 4.169, 'train_steps_per_second': 0.131, 'train_loss': 0.13820040559067445, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./data/bert-base-NER_model\\\\tokenizer_config.json',\n",
       " './data/bert-base-NER_model\\\\special_tokens_map.json',\n",
       " './data/bert-base-NER_model\\\\vocab.txt',\n",
       " './data/bert-base-NER_model\\\\added_tokens.json',\n",
       " './data/bert-base-NER_model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=ner_model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=TOKENIZER,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# Sauvegarde du modèle\n",
    "ner_model.save_pretrained(MODEL_PATH)\n",
    "TOKENIZER.save_pretrained(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Prédictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédictions sauvegardées avec succès.\n"
     ]
    }
   ],
   "source": [
    "def predict_and_save(dataset, output_file):\n",
    "    \"\"\"Prédit les étiquettes pour le dataset et les sauvegarde dans un fichier.\"\"\"\n",
    "    predictions = []\n",
    "    for example in dataset:\n",
    "        tokens = example[\"tokens\"]\n",
    "        inputs = TOKENIZER(tokens, truncation=True, is_split_into_words=True, return_tensors=\"pt\").to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            outputs = ner_model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predicted_ids = torch.argmax(logits, dim=-1).squeeze().tolist()\n",
    "        predicted_labels = [ID2LABEL[i] for i in predicted_ids]\n",
    "        predictions.append({\"tokens\": tokens, \"predictions\": predicted_labels})\n",
    "    \n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(predictions, f, indent=4)\n",
    "\n",
    "predict_and_save(ner_data[\"test\"], TESTING_OUTPUT_FILE)\n",
    "predict_and_save(ner_data[\"validation\"], VALIDATION_OUTPUT_FILE)\n",
    "\n",
    "print(\"Prédictions sauvegardées avec succès.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
